# train.csvをpandasのDataFrameに読み込んで中身を表示。
train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
train



# train.csvをpandasのDataFrameに読み込んで中身を表示。
train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
train



from collections import Counter

# 0～9の各数字の枚数を調べる。
count = Counter(train['label'])
count



import seaborn as sns

# 0～9の各数字の枚数をグラフにする。
sns.countplot(train['label'])



# 訓練データの1番目の要素を出力。
print(tr_x[0])



import matplotlib.pyplot as plt
%matplotlib inline

# 訓練データから50枚抽出してプロットする。
plt.figure(figsize=(12,10))
x, y = 20, 5 # 10列5行で出力。
for i in range(50):  
    plt.subplot(y, x, i+1)
    # 28×28にリサイズして描画する。
    plt.imshow(va_x[i].reshape((28,28)),interpolation='nearest')
plt.show()



# ニューラルネットワークの構築

# keras.modelsからSequentialをインポート
from tensorflow.keras.models import Sequential
# keras.layersからDense、Activationをインポート
from tensorflow.keras.layers import Dense, Activation

# Sequentialオブジェクトを生成。
model = Sequential()

# 第1層(隠れ層)
model.add(Dense(
    128,                     # ユニット数は128。
    input_dim=tr_x.shape[1], # 入力データの形状を指定。
    activation='sigmoid'     # 活性化関数はSigmoid。
))

# 第2層(出力層)
model.add(Dense(
    10,                  # ニューロン数はクラスの数と同数の10。
    activation='softmax' # マルチクラス分類に適したSoftmaxを指定。
))

model.compile(
    # 損失関数はクロスエントロピー誤差関数。
    loss='categorical_crossentropy',
    # オプティマイザーはAdam。
    optimizer='adam',
    # 学習評価として正解率を指定。
    metrics=['accuracy'])

# モデルの構造を出力。
model.summary()



# 学習を行う。
result = model.fit(tr_x, tr_y,                   # 訓練データと正解ラベル。
                   epochs=5,                     # 学習回数を5回にする。
                   batch_size=100,               # ミニバッチのサイズは100。
                   validation_data=(va_x, va_y), # 検証用のデータを指定。
                   verbose=1)                    # 学習の進捗を出力。



# テストデータで予測して結果をNumPy配列に代入する。
result = model.predict(test_x)


# 予測結果の確認とOne-Hotエンコーディングから数値への置き換え。

# 予測結果の先頭から5番目までを出力。
print(result[:5])

# 最大値のインデックス(予測した数字)を出力。
print([x.argmax() for x in result[:5]])
# 予測した数字をNumPy配列に代入する。
y_test = [x.argmax() for x in result]



!pip install hyperas


from hyperopt import hp
from hyperopt import Trials, tpe
from hyperas import optim
from hyperas.distributions import choice, uniform

def prepare_data():
    """データを用意する。
    
    """
    # prepare_data()とcreate_model()で使用する
    # 外部ライブラリはここでインポートする。
    import numpy as np
    import pandas as pd
    from sklearn.model_selection import KFold
    from tensorflow.keras.utils import to_categorical
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, Activation, Dropout

    # train.csvを読み込んでpandasのDataFrameに格納。
    train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
    train_x = train.drop(['label'], axis=1) # trainから画像データを抽出
    train_y = train['label']                # trainから正解ラベルを抽出

    # trainのデータを学習データとテストデータに分ける。
    kf = KFold(n_splits=4, shuffle=True, random_state=71)
    tr_idx, va_idx = list(kf.split(train_x))[0]
    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]
    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]

    # 画像のピクセル値を255.0で割って0～1.0の範囲にしてnumpy.arrayに変換。
    tr_x, va_x = np.array(tr_x / 255.0), np.array(va_x / 255.0)
    
    # 正解ラベルをone-hot表現に変換。
    tr_y = to_categorical(tr_y, 10)
    va_y = to_categorical(va_y, 10)

    return tr_x, tr_y, va_x, va_y

def create_model(tr_x, tr_y):
    """モデルを生成する。
    
    """
    # Sequentialオブジェクトを生成。
    model = Sequential()

    # 第1層を配置し、ユニット数を500または784とする。
    model.add(Dense(
        {{choice([500, 784])}},
        input_dim=tr_x.shape[1],
        activation='relu'
    ))
    model.add(Dropout(0.4))
    
    # 追加する層の数を0.1.2の中から探索。        
    if {{choice(['none', 'one', 'two'])}} == 'none':
        #noneがチョイスされたら層の追加は行わない。
        pass

    elif {{choice(['none', 'one', 'two'])}} == 'one':
        # oneが選択されたら層を1つ配置し、ユニット数を探索する。
        model.add(Dense(
            {{choice([100, 200])}},
        activation='relu'
        ))
        
    elif {{choice(['none', 'one', 'two'])}} == 'two':
        # twoが選択されたら層を2つ配置し、それぞれのユニット数を探索する。
        model.add(Dense(
            {{choice([100, 200])}},
        activation='relu'
        ))
        model.add(Dense(
            {{choice([25, 50])}},
        activation='relu'
        ))
        
    # 出力層を配置する。
    # クラス数が決まっているのでユニット数の探索は行わない。
    model.add(Dense(10, activation="softmax"))

    # モデルのコンパイル。
    # オプティマイザーはAdamとRMSpropを試す。
    model.compile(loss="categorical_crossentropy",
                  optimizer={{choice(['adam', 'rmsprop'])}},
                  metrics=["accuracy"])

    epoch = 10         # 学習の回数。
    batch_size = 100   # ミニバッチのサイズ。

    # 学習の実行。
    result = model.fit(tr_x, tr_y,
                       epochs=epoch,
                       batch_size=batch_size,
                       validation_data=(va_x, va_y),
                       verbose=0)

    # 探索時の精度を出力する。
    validation_acc = np.amax(result.history['val_accuracy']) 
    print('Accuracy in search:', validation_acc)

    # validation_accの値を最小化するように探索する。
    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}

# 探索の実行。
best_run, best_model = optim.minimize(model=create_model,
                                      data=prepare_data,
                                      algo=tpe.suggest,
                                      max_evals=20,
                                      eval_space=True,
                                      notebook_name='__notebook_source__',
                                      trials=Trials())



# 最も精度が優れていたモデルを出力。
print(best_model.summary())
# 最も精度が優れていたパラメーター値を出力。
print(best_run)

# 探索したモデルでテストデータを検証する。
_, _, va_x, va_y = prepare_data()
val_loss, val_acc = best_model.evaluate(va_x, va_y)
print("val_loss: ", val_loss) # 損失を出力。
print("val_acc: ", val_acc)   # 精度を出力。





import numpy as np
import pandas as pd

# train.csvを読み込んでpandasのDataFrameに格納。
train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
# trainから画像データを抽出してDataFrameオブジェクトに格納。
train_x = train.drop(['label'], axis=1)

# 画像のピクセル値を255.0で割って0～1.0の範囲にしてnumpy.arrayに変換。
train_x = np.array(train_x / 255.0)

# 画像データを2階テンソルを
# (高さ = 28px, 幅 = 28px , チャンネル = 1)の
# 3階テンソルに変換。
# グレースケールのためチャンネルは1。
tr_x = train_x.reshape(-1,28,28,1)



# フィルターの作成

# 縦方向のエッジを検出する3×3のフィルター
vertical_edge_fil = np.array([[-2, 1, 1],
                              [-2, 1, 1], 
                              [-2, 1, 1]],
                             dtype=ﬂoat)
# 横方向のエッジを検出する3×3のフィルター
horizontal_edge_fil = np.array([[1, 1, 1], 
                                [1, 1, 1],
                                [-2, -2, -2]],
                               dtype=ﬂoat)



# フィルターの適用

# フィルターを適用する画像のインデックス
img_id = 42

# フィルターを適用する画像のインデックス
img_id = 42
# 画像のピクセル値を取得
img_x = tr_x[img_id, :, :, 0]
img_height = 28 # 画像の縦サイズ
img_width = 28  # 画像の横サイズ
# 画像データを28×28の行列に変換
img_x = img_x.reshape(img_height, img_width)
# 縦エッジのフィルター適用後の値を代入する行列を用意
vertical_edge = np.zeros_like(img_x)
# 横エッジのィルター適用後の値を代入する行列を用意
horizontal_edge = np.zeros_like(img_x)

# 3×3のフィルターを適用
for h in range(img_height - 3):
    for w in range(img_width - 3):
        # フィルターを適用する領域を取得
        img_region = img_x[h:h + 3, w:w + 3]
        # 縦エッジのフィルターを適用
        vertical_edge[h + 1, w + 1] = np.dot(
            # 画像のピクセル値を1次元の配列に変換
            img_region.reshape(-1),
            # 縦エッジのフィルターを1次元の配列に変換
            vertical_edge_fil.reshape(-1)
        )
        # 横エッジのフィルターを適用
        horizontal_edge[h + 1, w + 1] = np.dot(
            # 画像のピクセル値を1次元の配列に変換
            img_region.reshape(-1),
            # 横エッジのフィルターを1次元の配列に変換
            horizontal_edge_fil.reshape(-1)
        )




# フィルター適用前と適用後の画像を出力する
import matplotlib.pyplot as plt
%matplotlib inline

# プロットエリアのサイズを設定
plt.ﬁgure(ﬁgsize=(8, 8))
# プロット図を縮小して図の間のスペースを空ける
plt.subplots_adjust(wspace=0.2)
plt.gray()

# 2×2のグリッドの上段左に元の画像をプロット
plt.subplot(2, 2, 1)
# 色相を反転させてプロットする
plt.pcolor(1 - img_x)
plt.xlim(-1, 29) # x軸を-1~29の範囲
plt.ylim(29, -1) # y軸を29~-1の範囲

# 2×2のグリッドの下段左に縦エッジ適用後をプロット
plt.subplot(2, 2, 3)
# 色相を反転させてプロットする
plt.pcolor(-vertical_edge)
plt.xlim(-1, 29)
plt.ylim(29, -1)

# 2×2のグリッドの下段右に横エッジ適用後をプロット
plt.subplot(2, 2, 4)
# 色相を反転させてプロットする
plt.pcolor(-horizontal_edge)
plt.xlim(-1, 29)
plt.ylim(29, -1)
plt.show()




import numpy as np
import pandas as pd
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import KFold

# train.csvを読み込んでpandasのDataFrameに格納。
train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
# trainから画像データを抽出してDataFrameオブジェクトに格納。
train_x = train.drop(['label'], axis=1)
# trainから正解ラベルを抽出してSeriesオブジェクトに格納。
train_y = train['label'] 
# test.csvを読み込んでpandasのDataFrameに格納。
test_x = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')

# trainのデータを学習データとテストデータに分ける。
kf = KFold(n_splits=4, shuffle=True, random_state=71)
tr_idx, va_idx = list(kf.split(train_x))[0]
tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]
tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]

# 画像のピクセル値を255.0で割って0～1.0の範囲にしてnumpy.arrayに変換。
tr_x, va_x = np.array(tr_x / 255.0), np.array(va_x / 255.0)

# 画像データを2階テンソルを
# (高さ = 28px, 幅 = 28px , チャンネル = 1)の
# 3階テンソルに変換。
# グレースケールのためチャンネルは1。
tr_x = tr_x.reshape(-1,28,28,1)
va_x = va_x.reshape(-1,28,28,1)

# 正解ラベルをOne-Hot表現に変換。
tr_y = to_categorical(tr_y, 10) # numpy.ndarrayオブジェクト
va_y = to_categorical(va_y, 10) # numpy.ndarrayオブジェクト

# x_train、y_train、x_testの形状を出力。
print(tr_x.shape)
print(tr_y.shape)
print(va_x.shape)
print(va_y.shape)



# 畳み込みニューラルネットワーク

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D,Dense, Flatten

model = Sequential()                 # Sequentialオブジェクトの生成

# 第1層
model.add(
    Conv2D(filters=32,               # フィルターの数
           kernel_size=(5, 5),       # 5×5のフィルターを使用
           padding='same',           # ゼロパディングを行う
           input_shape=(28, 28, 1),  # 入力データの形状         
           activation='relu'         # 活性化関数はReLU
           ))

# Flatten層
model.add(Flatten())

# 出力層
model.add(Dense(10,                  # 出力層のニューロン数は10
                activation='softmax' # 活性化関数はsoftmax
               ))
    
# オブジェクトのコンパイル
model.compile(
    loss='categorical_crossentropy', # 損失の基準は交差エントロピー誤差
    optimizer='rmsprop',             # オプティマイザーはRMSprop
    metrics=['accuracy'])            # 学習評価として正解率を指定

# モデルの構造を出力。
model.summary()



# 学習を行って結果を出力
history = model.fit(
    tr_x,             # 訓練データ
    tr_y,             # 正解ラベル
    epochs=30,        # 学習を繰り返す回数
    batch_size=100,   # ミニバッチの数
    verbose=1,        # 学習の進捗状況を出力する
    validation_data=(
    va_x, va_y        # 検証用データの指定
    ))




# 損失と正解率（精度）の推移をグラフにする

%matplotlib inline
import matplotlib.pyplot as plt

# プロット図のサイズを設定
plt.ﬁgure(ﬁgsize=(15, 6))
# プロット図を縮小して図の間のスペースを空ける
plt.subplots_adjust(wspace=0.2)

# 1×2のグリッドの左(1,2,1)の領域にプロット
plt.subplot(1, 2, 1)
# 訓練データの損失(誤り率)をプロット
plt.plot(history.history['loss'],
         label='training',
         color='black')
# テストデータの損失(誤り率)をプロット
plt.plot(history.history['val_loss'],
         label='test',
         color='red')
plt.ylim(0, 1)       # y軸の範囲
plt.legend()         # 凡例を表示
plt.grid()           # グリッド表示
plt.xlabel('epoch')  # x軸ラベル
plt.ylabel('loss')   # y軸ラベル

# 1×2のグリッドの右(1,2,21)の領域にプロット
plt.subplot(1, 2, 2)
# 訓練データの正解率をプロット
plt.plot(history.history['accuracy'],
         label='training',
         color='black')
# テストデータの正解率をプロット
plt.plot(history.history['val_accuracy'],
         label='test',
         color='red')
plt.ylim(0.5, 1)     # y軸の範囲
plt.legend()         # 凡例を表示
plt.grid()           # グリッド表示
plt.xlabel('epoch')  # x軸ラベル
plt.ylabel('acc')    # y軸ラベル
plt.show()




import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from tensorflow.keras.utils import to_categorical

# train.csvを読み込んでpandasのDataFrameに格納
train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
train_x = train.drop(['label'], axis=1) # trainから画像データを抽出
train_y = train['label']                # trainから正解ラベルを抽出
test_x = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')

# trainのデータを学習データとテストデータに分ける。
kf = KFold(n_splits=4, shuffle=True, random_state=123)
tr_idx, va_idx = list(kf.split(train_x))[0]
tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]
tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]

# 画像のピクセル値を255.0で割って0～1.0の範囲にしてnumpy.arrayに変換
tr_x, va_x = np.array(tr_x / 255.0), np.array(va_x / 255.0)

# 画像データの2階テンソルを
# (高さ = 28px, 幅 = 28px , チャンネル = 1)の
# 3階テンソルに変換
# グレースケールのためチャンネルは1。
tr_x = tr_x.reshape(-1,28,28,1)
va_x = va_x.reshape(-1,28,28,1)

# 正解ラベルをone-hot表現に変換
tr_y = to_categorical(tr_y, 10)
va_y = to_categorical(va_y, 10)



# モデルを生成する
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten # core layers
from tensorflow.keras.layers import Conv2D, MaxPooling2D    # convolution layers

# Sequentialオブジェクトを生成
model = Sequential()

# 第1層:畳み込み層
model.add(Conv2D(filters=32,
                 kernel_size=(5,5),
                 padding='same', 
                 activation='relu',
                 input_shape=(28,28,1)))

# 第2層:畳み込み層
model.add(Conv2D(filters = 64,
                 kernel_size = (7,7),
                 padding='same', 
                 activation='relu'))

# 第3層:プーリング層
model.add(MaxPooling2D(pool_size=(2,2)))

# ドロップアウト
model.add(Dropout(0.5))

# 第4層:畳み込み層
model.add(Conv2D(filters=64,
                 kernel_size=(5,5),
                 padding='same', 
                 activation='relu'))

# 第5層:畳み込み層
model.add(Conv2D(filters = 32,
                 kernel_size = (3,3),
                 padding='same', 
                 activation='relu'))

# 第6層:プーリング層
model.add(MaxPooling2D(pool_size=(2,2)))

# ドロップアウト
model.add(Dropout(0.55))

# Flatten層
model.add(Flatten())

# 第7層：全結合層
model.add(Dense(700, activation='relu'))
model.add(Dropout(0.3))

# 第8層：全結合層
model.add(Dense(150, activation='relu'))
model.add(Dropout(0.35))

# 第10層：出力層
model.add(Dense(10, activation = "softmax"))

# モデルのコンパイル
# オプティマイザーはAdam
momentum = 0.5
model.compile(loss="categorical_crossentropy",
              optimizer='adam',
              metrics=["accuracy"])

# モデルの構造を出力。
model.summary()



