{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "前処理.ipynb のコピー のコピー",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenken0830/preprocessing/blob/master/%E5%89%8D%E5%87%A6%E7%90%86_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc4YKLxn7Anb"
      },
      "source": [
        "# Chapter2-2　テーブルデータの前処理\n",
        "\n",
        "※サポートサイトから2章用のデータをダウンロードし、「sales201907.csv」「sales201907.tsv」をセッションストレージ（P.312）にアップして進めてください。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5xiNEKwmR2o",
        "outputId": "5a3d23f0-6525-4a48-a32d-0cdd943f0b17"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V0g1im1oYBA"
      },
      "source": [
        "# 必要なライブラリをインポート\n",
        "import pandas as pd\n",
        "#csvから読み込む\n",
        "df = pd.read_csv('sales201907.csv')\n",
        "#tsvから読み込む\n",
        "df = pd.read_table('sales201907.tsv')\n",
        "#tsvをread_csvで読み込む\n",
        "df = pd.read_csv('sales201907.tsv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQKyU7de7pzt"
      },
      "source": [
        "# !注意！実行するとエラーが出ます。\n",
        "#エンコードがsjisの場合\n",
        "df = pd.read_csv('sales201907.csv', encoding='sjis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0L6miE1747I"
      },
      "source": [
        "# Chapter2-3　データの結合と集約\n",
        "\n",
        "※サポートサイトから2章用のデータをダウンロードし、「sales201907.csv」「sales201907.tsv」をセッションストレージ（P.312）にアップして進めてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUBmkrokNUEC"
      },
      "source": [
        "## 2-3-1　縦結合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwllvEBQsjrp"
      },
      "source": [
        "import pandas as pd\n",
        "#3ヶ月分読み込む\n",
        "df_201907 = pd.read_csv('sales201907.csv')\n",
        "df_201908 = pd.read_csv('sales201908.csv')\n",
        "df_201909 = pd.read_csv('sales201909.csv')\n",
        "#縦に結合\n",
        "df = pd.concat([df_201907, df_201908, df_201909])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzrNkUb7Na1O"
      },
      "source": [
        "## 2-3-2　ID単位で値を集約"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veqKyhnmS4iW"
      },
      "source": [
        "#### 2-3-2-1　集約対象が数値である場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0CnkWtb8Art"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAq9khfuszlq"
      },
      "source": [
        "pd.pivot_table(df, index='顧客ID', columns='商品名', aggfunc='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAd8j-kjNfj2"
      },
      "source": [
        "## 2-3-3　横結合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEu-CnUk0Aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3d06bdbd-d746-4b86-8acd-b1c3564df795"
      },
      "source": [
        "#属性データ読み込み\n",
        "df_zokusei = pd.read_csv('zokusei.csv')\n",
        "print (df_zokusei)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    顧客ID        生年月日  性別  都道府県  市区町村\n",
            "0  10001   1982/2/25   1  神奈川県   川崎市\n",
            "1  10002    1991/8/2   1   埼玉県   朝霞市\n",
            "2  10003  1976/10/21   1  神奈川県  相模原市\n",
            "3  10004   1999/1/22   2   千葉県   千葉市\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDwJ1kXS0fq-"
      },
      "source": [
        "#ID単位で集約したテーブルに属性を紐づけます\n",
        "pd.merge(\n",
        "    df_zokusei,#属性データ\n",
        "    pd.pivot_table(df, index='顧客ID', columns='商品名', aggfunc='sum').reset_index(),#顧客IDで紐付けるためindexを解除しておく\n",
        "    on = '顧客ID',\n",
        "    how = 'left' #左を優先して結合\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL0h0Bjg8joY"
      },
      "source": [
        "# Chapter2-4　テーブルデータの理解\n",
        "\n",
        "※サポートサイトから2章用のデータをダウンロードし、「adult.data」をセッションストレージ（P.312）にアップして進めてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf1U3JPlNktO"
      },
      "source": [
        "## 2-4-1　探索的データアナリシス（EDA）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBXirdu707uP"
      },
      "source": [
        "########################\n",
        "#サンプルデータ  準備\n",
        "#calidornia housing\n",
        "########################\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#欠損をランダムに作成するため乱数オブジェクト作成\n",
        "rng = np.random.RandomState(0)\n",
        "#california_housing 読み込む\n",
        "dataset = fetch_california_housing()\n",
        "#説明変数を取得\n",
        "X_full = dataset.data\n",
        "#被説明変数を取得\n",
        "y_full = dataset.target\n",
        "#全てのレコードでは大きいので10サンプルごとに抽出\n",
        "X_full = X_full[::10]\n",
        "y_full = y_full[::10]\n",
        "#欠損作成のためにレコード数とカラム数を取得\n",
        "n_full_samples, n_full_features = X_full.shape\n",
        "missing_full_samples = np.arange(n_full_samples)\n",
        "#意図的にレコードの半分を欠損させる\n",
        "missing_full_samples = np.random.choice(missing_full_samples,len(missing_full_samples)//2,replace=False)\n",
        "X_missing = X_full[missing_full_samples].copy()\n",
        "y = y_full\n",
        "n_samples, n_features = X_missing.shape\n",
        "#欠損となる列をランダムに決める\n",
        "missing_features = rng.choice(n_features, n_samples, replace=True)\n",
        "#欠損代入\n",
        "missing_samples = np.arange(n_samples)\n",
        "X_missing[missing_samples, missing_features] = np.nan\n",
        "#欠損させない配列\n",
        "X_not_missing = X_full[np.setdiff1d(np.arange(n_full_samples), missing_full_samples)].copy()\n",
        "#欠損させる配列とさせない配列を結合\n",
        "X = np.concatenate([X_not_missing,X_missing])\n",
        "#データフレーム化\n",
        "df_california = pd.DataFrame(np.concatenate([X,y.reshape(-1,1)],axis=1))\n",
        "df_california.columns=dataset.feature_names+['Target']\n",
        "\n",
        "########################\n",
        "#サンプルデータ  準備\n",
        "#Adult Data Set\n",
        "########################\n",
        "df_adult = pd.read_csv('adult.data',header=None)\n",
        "#変数名付与\n",
        "df_adult.columns = [\"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
        "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
        "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cKeFYN7NshJ"
      },
      "source": [
        "## 2-4-2　テーブル全体の理解"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gg01NUi87Te"
      },
      "source": [
        "#テーブルのサイズ表示\n",
        "print (df_california.shape)\n",
        "#カラムごとの欠損ではないレコード数 とデータ型\n",
        "print (df_california.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoUaXm029AJd"
      },
      "source": [
        "#カラムごと欠損数\n",
        "print (df_california.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylG2T2c-NxV3"
      },
      "source": [
        "## 2-4-3　数値変数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c80QBCi89Cnm"
      },
      "source": [
        "#統計量算出\n",
        "df_california.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01KITs8o9GgX"
      },
      "source": [
        "#変数の箱ひげ図を描く\n",
        "plt.figure(figsize=(14,10))\n",
        "for i in np.arange((df_california.shape[1])):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.boxplot(df_california.dropna().iloc[:,i])\n",
        "    plt.title(df_california.columns[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKbTLyR89L1O"
      },
      "source": [
        "#変数のヒストグラムを描く\n",
        "plt.figure(figsize=(14,10))\n",
        "for i in np.arange((df_california.shape[1])):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.hist(df_california.dropna().iloc[:,i])\n",
        "    plt.title(df_california.columns[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdS8zRE9N1Z_"
      },
      "source": [
        "## 2-4-4　カテゴリカル変数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWyBO5js9Pc2"
      },
      "source": [
        "#カテゴリカル変数の要約を確認\n",
        "df_adult.describe(include='O')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esJ8BDY-9S6X"
      },
      "source": [
        "#数値・カテゴリ変数同時に行う\n",
        "df_adult.describe(include='all').T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7ksUE0k9WLP"
      },
      "source": [
        "#プロットエリア定義\n",
        "plt.figure(figsize=(20,20))\n",
        "#カテゴリカル変数でヒストグラムを書く\n",
        "for i,j in enumerate(df_adult.describe(include='O').columns):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.barh(width=df_adult.loc[:,j].value_counts(),\n",
        "         y=df_adult.loc[:,j].value_counts().index)\n",
        "    plt.title(j,fontdict={'fontsize': 20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzd-y3cpN6TM"
      },
      "source": [
        "## 2-4-5　変数間の相関"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIzr5_Hx9X7n"
      },
      "source": [
        "df_california.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8wChLDZ9b8v"
      },
      "source": [
        "#ヒートマップを作成\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(df_california.corr(),cmap=\"YlGnBu\",linewidths=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YZfd4cb9l5F"
      },
      "source": [
        "# Chapter2-5　カテゴリカル変数の処理\n",
        "\n",
        "※サポートサイトから2章用のデータをダウンロードし、「adult.data」をセッションストレージ（P.312）にアップして進めてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aD9wowx9eBx"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brtZKTrAN_rP"
      },
      "source": [
        "## 2-5-1　順序ラベル・エンコーディング"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5BIBdJa91pu"
      },
      "source": [
        "import pandas as pd\n",
        "#コーヒーサイズデータフレーム作成\n",
        "df = pd.DataFrame({\n",
        "    'SIZE': ['L', 'M', 'S', 'L'],\n",
        "    'PRICE': ['250', '200', '150', '250']\n",
        "})\n",
        "\n",
        "#表示\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTcDsEDN95nu"
      },
      "source": [
        "#category encoder インポート\n",
        "import category_encoders as ce\n",
        "#マップを辞書で学習\n",
        "mapping = [{'col': 'SIZE', 'mapping': {'S': 0, 'M': 1, 'L': 2}}]\n",
        "#エンコーダーをインスタンス化\n",
        "enc = ce.OrdinalEncoder(mapping=mapping)\n",
        "#マップを学習\n",
        "enc.fit(df)\n",
        "#変換\n",
        "enc.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keRdIZcfOD2v"
      },
      "source": [
        "## 2-5-2　One-Hotエンコーディング"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQkQ3JXF9-Bf"
      },
      "source": [
        "#df_adultを読み込む\n",
        "df_adult = pd.read_csv('adult.data', header=None)\n",
        "df_adult.columns = [\n",
        "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\", \"MaritalStatus\",\n",
        "    \"Occupation\", \"Relationship\", \"Race\", \"Gender\", \"CapitalGain\",\n",
        "    \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
        "]\n",
        "\n",
        "#OneHotEncoder 1インスタンス化\n",
        "#use_cat_names をTrueとすることで変数名が元のカテゴリ名に対応する\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "#学習\n",
        "encoder.fit(df_adult['MaritalStatus'])\n",
        "#変換\n",
        "encoder.transform(df_adult['MaritalStatus'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C5KRJrzTb5V"
      },
      "source": [
        "#####2-5-2-1 データフレーム全体に適用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ht93Zaa-Cj2"
      },
      "source": [
        "#df全体に適用\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "#学習\n",
        "encoder.fit(df_adult)\n",
        "#変換\n",
        "encoder.transform(df_adult)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a6SqHZOTgTr"
      },
      "source": [
        "####2-5-2-2 ログデータやトランザクションデータの集約への応用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzXUASCP-K6d"
      },
      "source": [
        "#購買トランザクション読み込み\n",
        "df = pd.read_csv('sales201907.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO2HwuRy-NGQ"
      },
      "source": [
        "#df全体に適用\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "#学習\n",
        "encoder.fit(df.drop('購買日時', axis=1))\n",
        "#変換\n",
        "df_enc = encoder.transform(df.drop('購買日時', axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYxg8_Zq-SUO"
      },
      "source": [
        "#pivotで集約する\n",
        "pd.pivot_table(df_enc, index='顧客ID',aggfunc='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIVeYGz-OLPH"
      },
      "source": [
        "## 2-5-3 ターゲット・エンコーディング"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJc2IOM7-UF-"
      },
      "source": [
        "#データをトレーニング・テストに分ける\n",
        "from sklearn.model_selection import train_test_split\n",
        "#NativeCountry取得\n",
        "X = df_adult['NativeCountry']\n",
        "#教師データをOneHotEncodingしておく\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "y = encoder.fit_transform(df_adult['Income']).iloc[:, 1]\n",
        "#データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0)\n",
        "#ターゲットエンコーダ インスタンス化\n",
        "encoder = ce.TargetEncoder()\n",
        "#トレーニングデータで学習\n",
        "encoder.fit(X_train,y_train)\n",
        "#トレーニングを変換\n",
        "X_train_enc = encoder.transform(X_train)\n",
        "#テストを変換\n",
        "X_test_enc = encoder.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkib6Q_a-WJ2"
      },
      "source": [
        "#元のデータと比較してみる\n",
        "pd.concat([X_train, X_train_enc], axis=1).drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uE-rFIW-jcU"
      },
      "source": [
        "# Chapter2-6 欠損値の処理\n",
        "\n",
        "Chapter 2-5でcategory_encoders をインストールしていない方はインストールしてください。\n",
        "\n",
        "※サポートサイトから2章用のデータをダウンロードし、「adult.data」をセッションストレージ（P.312）にアップして進めてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD3h7RWe-eLP"
      },
      "source": [
        "# インストールしていない方用 # を外して実行してください\n",
        "# !pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYxU8ZwyOQuY"
      },
      "source": [
        "## 2-6-2 基本的な欠損処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwm1OqNx-8W4"
      },
      "source": [
        "!pip install missingno"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zx3VBIA_FY_"
      },
      "source": [
        "## ここで「You must restart the runtime in order to use newly installed versions.」というメッセージが出たら、「RESTART RUNTIME」ボタンをクリックしてランタイムを再起動してください。\n",
        "!pip install -U scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOSZM6gI_HN_"
      },
      "source": [
        "#データをトレーニング・テストに分けるモジュール\n",
        "from sklearn.model_selection import train_test_split\n",
        "#ロジスティック回帰モデル\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#正答率算出\n",
        "from sklearn.metrics import accuracy_score\n",
        "#category encoder インポート\n",
        "import category_encoders as ce\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#欠損埋めモジュール\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "import missingno as mno\n",
        "\n",
        "########################\n",
        "#サンプルデータ  準備\n",
        "#Adult Data Set\n",
        "########################\n",
        "df_adult = pd.read_csv('adult.data', header=None)\n",
        "#変数名付与\n",
        "df_adult.columns = [\n",
        "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\", \"MaritalStatus\",\n",
        "    \"Occupation\", \"Relationship\", \"Race\", \"Gender\", \"CapitalGain\",\n",
        "    \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
        "]\n",
        "\n",
        "#欠損率を20%と設定\n",
        "p = 0.2\n",
        "#架空の欠損データ生成\n",
        "from numpy.random import *\n",
        "seed(1)\n",
        "x = pd.Series(np.random.uniform(0.0, 1.0, len(df_adult)))\n",
        "x.index = df_adult.index\n",
        "\n",
        "#MCAR作成\n",
        "df_adult['Age_mcar'] = np.where(x < p, np.nan, df_adult['Age'])\n",
        "\n",
        "#MAR作成\n",
        "#全体の欠損率が20%、女性の欠損率が30%となるように設定\n",
        "p_f = 0.3\n",
        "p_m = (round(len(df_adult) * p) - df_adult.Gender.value_counts()[1] * p_f\n",
        "       ) / df_adult.Gender.value_counts()[0]\n",
        "\n",
        "#男性\n",
        "ix = df_adult['Gender'] == ' Male'\n",
        "seed(2)\n",
        "x = pd.Series(np.random.uniform(0.0, 1.0, len(df_adult)))\n",
        "x.index = df_adult.index\n",
        "df_adult['Age_mar'] = np.where((x < p_m) & (ix), np.nan, df_adult['Age'])\n",
        "\n",
        "#女性\n",
        "ix = df_adult['Gender'] == ' Male'\n",
        "seed(3)\n",
        "x = pd.Series(np.random.uniform(0.0, 1.0, len(df_adult)))\n",
        "x.index = df_adult.index\n",
        "df_adult['Age_mar'] = np.where((x < p_f) & (~ix), np.nan, df_adult['Age_mar'])\n",
        "\n",
        "#MNAR\n",
        "#40歳以上の一部を欠損とする\n",
        "ix = df_adult['Age'] >= 40\n",
        "p_40 = round(len(df_adult) * p) / (ix).sum()\n",
        "seed(4)\n",
        "x = pd.Series(np.random.uniform(0.0, 1.0, len(df_adult)))\n",
        "x.index = df_adult.index\n",
        "#30%欠損\n",
        "df_adult['Age_mnar'] = np.where((x < p_40) & (ix), np.nan, df_adult['Age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UAEBMPZ_h_q"
      },
      "source": [
        "#ターゲット変数1/0エンコーディング\n",
        "df_adult['Income'] = (df_adult['Income'] == ' >50K').astype(int)\n",
        "#特徴量取得\n",
        "X_adult = df_adult.drop(['Income'], axis=1)\n",
        "#ターゲット変数を取得\n",
        "y_adult = df_adult['Income']\n",
        "#訓練・検証データを分離\n",
        "X_adult_train, X_adult_test, y_adult_train, y_adult_test = train_test_split(\n",
        "    X_adult, y_adult, test_size=0.2, random_state=1)\n",
        "\n",
        "#ターゲットエンコーダ インスタンス化\n",
        "encoder = ce.TargetEncoder(cols=['Education', 'Occupation', 'NativeCountry'])\n",
        "enc = encoder.fit(X_adult_train, y_adult_train)\n",
        "X_adult_train = enc.transform(X_adult_train)\n",
        "X_adult_test = enc.transform(X_adult_test)\n",
        "\n",
        "#One-Hotエンコーディング インスタンス化\n",
        "encoder = ce.OneHotEncoder(\n",
        "    cols=['WorkClass', 'MaritalStatus', 'Relationship', 'Race', 'Gender'],\n",
        "    use_cat_names=True)\n",
        "enc = encoder.fit(X_adult_train)\n",
        "X_adult_train = enc.transform(X_adult_train)\n",
        "X_adult_test = enc.transform(X_adult_test)\n",
        "\n",
        "#One-Hotで冗長になった変数を落とす\n",
        "drop_l = [\n",
        "    [col for col in X_adult_train.columns if col.find('WorkClass') >= 0][0], [\n",
        "        col for col in X_adult_train.columns if col.find('MaritalStatus') >= 0\n",
        "    ][0], [\n",
        "        col for col in X_adult_train.columns if col.find('Relationship') >= 0\n",
        "    ][0], [col for col in X_adult_train.columns if col.find('Race') >= 0][0],\n",
        "    [col for col in X_adult_train.columns if col.find('Gender') >= 0][0]\n",
        "]\n",
        "X_adult_train = X_adult_train.drop(drop_l, axis=1)\n",
        "X_adult_test = X_adult_test.drop(drop_l, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxtx719d_jpR"
      },
      "source": [
        "# 欠損を含むカラムがあるか確認\n",
        "print(df_adult.isnull().any())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg_0CnTg_5hR"
      },
      "source": [
        "# カラムごとの欠損の個数を確認\n",
        "print(df_adult.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuXIQkK_8fZ"
      },
      "source": [
        "mno.matrix(df_adult, figsize = (20, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14p1tinOOazg"
      },
      "source": [
        "## 2-6-3 欠損を除去する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrvwYebk__Y6"
      },
      "source": [
        "#欠損を含む行及び列を落とす (例としてMCARの場合)\n",
        "#データ作成\n",
        "X_adult_train_mcar = X_adult_train.drop(['Age','Age_mar','Age_mnar'],axis=1)\n",
        "print (X_adult_train_mcar.isnull().sum())\n",
        "\n",
        "#行を落とす\n",
        "X_adult_train_mcar_dropnar = X_adult_train_mcar.dropna()\n",
        "print (X_adult_train_mcar_dropnar.isnull().sum())\n",
        "\n",
        "#列を落とす(axis=1オプション)\n",
        "X_adult_train_mcar_dropnac = X_adult_train_mcar.dropna(axis=1)\n",
        "print (X_adult_train_mcar_dropnac.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_ReanfpOdLQ"
      },
      "source": [
        "## 2-6-4 欠損に値を代入する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UI2OPxGOylZ"
      },
      "source": [
        "### 2-6-4-1 ある定数を代入する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnZVwPcHAGIq"
      },
      "source": [
        "#元のデータを消さないように\n",
        "X_adult_train_fillna = X_adult_train.copy()\n",
        "X_adult_test_fillna = X_adult_test.copy()\n",
        "\n",
        "#平均値で埋める\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "missing_cols = ['Age_mcar', 'Age_mar', 'Age_mnar']\n",
        "#訓練データから平均値を算出\n",
        "imputer.fit(X_adult_train_fillna[missing_cols])\n",
        "#訓練データ\n",
        "X_adult_train_fillna[[col + '_mean' for col in missing_cols]] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_train_fillna[missing_cols]),\n",
        "    index=X_adult_train.index)\n",
        "#テストデータ\n",
        "X_adult_test_fillna[[col + '_mean' for col in missing_cols]] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_test_fillna[missing_cols]),\n",
        "    index=X_adult_test.index)\n",
        "\n",
        "#中央値で埋める\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "missing_cols = ['Age_mcar', 'Age_mar', 'Age_mnar']\n",
        "imputer.fit(X_adult_train_fillna[missing_cols])\n",
        "imputer.fit(X_adult_train_fillna[missing_cols])\n",
        "#訓練データ\n",
        "X_adult_train_fillna[[col + '_median' for col in missing_cols]] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_train_fillna[missing_cols]),\n",
        "    index=X_adult_train.index)\n",
        "#テストデータ\n",
        "X_adult_test_fillna[[col + '_median' for col in missing_cols]] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_test_fillna[missing_cols]),\n",
        "    index=X_adult_test.index)\n",
        "\n",
        "#最頻値で埋める\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "missing_cols = ['Age_mcar', 'Age_mar', 'Age_mnar']\n",
        "imputer.fit(X_adult_train_fillna[missing_cols])\n",
        "#訓練データ\n",
        "X_adult_train_fillna[[col + '_mode' for col in missing_cols]] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_train_fillna[missing_cols]),\n",
        "    index=X_adult_train.index)\n",
        "#テストデータ\n",
        "X_adult_test_fillna[[col + '_mode' for col in missing_cols]] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_test_fillna[missing_cols]),\n",
        "    index=X_adult_test.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOzUV-yCAI5g"
      },
      "source": [
        "#MARの代入前後の分布\n",
        "plt.figure(figsize=(14, 7))\n",
        "for i, col in enumerate(\n",
        "    ['Age_mar', 'Age_mar_mean', 'Age_mar_median', 'Age_mar_mode']):\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.hist(\n",
        "        X_adult_train_fillna['Age'],\n",
        "        alpha=0.7,\n",
        "        label='Complete Data',\n",
        "        bins=range(0, 100, 10))\n",
        "    plt.legend()\n",
        "    plt.hist(X_adult_train_fillna[col], alpha=0.7, bins=range(0, 100, 10))\n",
        "    plt.grid()\n",
        "    plt.title(col)\n",
        "    plt.xticks([0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "josQvkKaO2tJ"
      },
      "source": [
        "### 2-6-4-2 他の変数から推定する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_nG4MhbAUUa"
      },
      "source": [
        "#sklearnのLinearRegressionモジュール読み込む\n",
        "from sklearn.linear_model import LinearRegression\n",
        "#線形回帰のインスタンス化\n",
        "reg1 = LinearRegression()\n",
        "reg2 = LinearRegression()\n",
        "reg3 = LinearRegression()\n",
        "\n",
        "#MCARに対して処理を実行\n",
        "#使用しない特徴量のリスト特にターゲットエンコーディングした特徴量は除く\n",
        "ix = X_adult_train['Age_mcar'].isnull()\n",
        "drop = ['Education', 'Occupation', 'NativeCountry'\n",
        "        ] + ['Age', 'Age_mcar', 'Age_mar', 'Age_mnar', 'fnlwgt']\n",
        "x1 = X_adult_train[~ix].drop(drop, axis=1)\n",
        "x2 = X_adult_train.loc[x1.index, 'Age_mcar']\n",
        "\n",
        "#線形回帰\n",
        "reg1.fit(x1, x2)\n",
        "\n",
        "#訓練データ予測する\n",
        "X_adult_train_fillna['Age_mcar_reg'] = pd.Series(\n",
        "    reg1.predict(X_adult_train[ix].drop(drop, axis=1)),\n",
        "    X_adult_train[ix].index)\n",
        "X_adult_train_fillna['Age_mcar_reg'] = X_adult_train_fillna[\n",
        "    'Age_mcar_reg'].fillna(X_adult_train_fillna['Age'])\n",
        "#検証データ予測する\n",
        "ixt = X_adult_test['Age_mcar'].isnull()\n",
        "X_adult_test_fillna['Age_mcar_reg'] = pd.Series(\n",
        "    reg1.predict(X_adult_test[ixt].drop(drop, axis=1)),\n",
        "    X_adult_test[ixt].index)\n",
        "X_adult_test_fillna['Age_mcar_reg'] = X_adult_test_fillna[\n",
        "    'Age_mcar_reg'].fillna(X_adult_test_fillna['Age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkex72AiAig1"
      },
      "source": [
        "#MARに対して処理を実行\n",
        "#使用しない特徴量のリスト特にターゲットエンコーディングした特徴量は除く\n",
        "ix = X_adult_train['Age_mar'].isnull()\n",
        "drop = ['Education', 'Occupation', 'NativeCountry'\n",
        "        ] + ['Age', 'Age_mcar', 'Age_mar', 'Age_mnar', 'fnlwgt']\n",
        "x1 = X_adult_train[~ix].drop(drop, axis=1)\n",
        "x2 = X_adult_train.loc[x1.index, 'Age_mar']\n",
        "\n",
        "#線形回帰\n",
        "reg2.fit(x1, x2)\n",
        "\n",
        "#訓練データ予測する\n",
        "X_adult_train_fillna['Age_mar_reg'] = pd.Series(\n",
        "    reg2.predict(X_adult_train[ix].drop(drop, axis=1)),\n",
        "    X_adult_train[ix].index)\n",
        "X_adult_train_fillna['Age_mar_reg'] = X_adult_train_fillna[\n",
        "    'Age_mar_reg'].fillna(X_adult_train_fillna['Age'])\n",
        "#検証データ予測する\n",
        "ixt = X_adult_test['Age_mar'].isnull()\n",
        "X_adult_test_fillna['Age_mar_reg'] = pd.Series(\n",
        "    reg1.predict(X_adult_test[ixt].drop(drop, axis=1)),\n",
        "    X_adult_test[ixt].index)\n",
        "X_adult_test_fillna['Age_mar_reg'] = X_adult_test_fillna['Age_mar_reg'].fillna(\n",
        "    X_adult_test_fillna['Age'])\n",
        "\n",
        "#MNARに対して処理を実行\n",
        "#使用しない特徴量のリスト特にターゲットエンコーディングした特徴量は除く\n",
        "ix = X_adult_train['Age_mnar'].isnull()\n",
        "drop = ['Education', 'Occupation', 'NativeCountry'\n",
        "        ] + ['Age', 'Age_mcar', 'Age_mar', 'Age_mnar', 'fnlwgt']\n",
        "x1 = X_adult_train[~ix].drop(drop, axis=1)\n",
        "x2 = X_adult_train.loc[x1.index, 'Age_mnar']\n",
        "#線形回帰\n",
        "reg3.fit(x1, x2)\n",
        "\n",
        "#訓練データ予測する\n",
        "X_adult_train_fillna['Age_mnar_reg'] = pd.Series(\n",
        "    reg3.predict(X_adult_train[ix].drop(drop, axis=1)),\n",
        "    X_adult_train[ix].index)\n",
        "X_adult_train_fillna['Age_mnar_reg'] = X_adult_train_fillna[\n",
        "    'Age_mnar_reg'].fillna(X_adult_train_fillna['Age'])\n",
        "#検証データ予測する\n",
        "ixt = X_adult_test['Age_mnar'].isnull()\n",
        "X_adult_test_fillna['Age_mnar_reg'] = pd.Series(\n",
        "    reg1.predict(X_adult_test[ixt].drop(drop, axis=1)),\n",
        "    X_adult_test[ixt].index)\n",
        "X_adult_test_fillna['Age_mnar_reg'] = X_adult_test_fillna[\n",
        "    'Age_mnar_reg'].fillna(X_adult_test_fillna['Age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iJ4i1fyAukz"
      },
      "source": [
        "##################MCAR 埋める##################\n",
        "#使用しない特徴量のリスト特にターゲットエンコーディングした特徴量は除く\n",
        "drop = ['Education', 'Occupation', 'NativeCountry'\n",
        "        ] + ['Age', 'Age_mar', 'Age_mnar', 'fnlwgt']\n",
        "\n",
        "#KNNImputerインスタンス化\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "#訓練\n",
        "imputer.fit(X_adult_train.drop(drop, axis=1))\n",
        "#訓練データに代入\n",
        "X_adult_train_fillna['Age_mcar_knn'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_train.drop(drop, axis=1)),\n",
        "    index=X_adult_train.drop(drop, axis=1).index,\n",
        "    columns=X_adult_train.drop(drop, axis=1).columns)['Age_mcar']\n",
        "\n",
        "#検証データに代入\n",
        "X_adult_test_fillna['Age_mcar_knn'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_test.drop(drop, axis=1)),\n",
        "    index=X_adult_test.drop(drop, axis=1).index,\n",
        "    columns=X_adult_test.drop(drop, axis=1).columns)['Age_mcar']\n",
        "\n",
        "##################MAR 埋める##################\n",
        "#使用しない特徴量のリスト特にターゲットエンコーディングした特徴量は除く\n",
        "drop = ['Education', 'Occupation', 'NativeCountry'\n",
        "        ] + ['Age', 'Age_mcar', 'Age_mnar', 'fnlwgt']\n",
        "\n",
        "#KNNImputerインスタンス化\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "#訓練\n",
        "imputer.fit(X_adult_train.drop(drop, axis=1))\n",
        "#訓練データに代入\n",
        "X_adult_train_fillna['Age_mar_knn'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_train.drop(drop, axis=1)),\n",
        "    index=X_adult_train.drop(drop, axis=1).index,\n",
        "    columns=X_adult_train.drop(drop, axis=1).columns)['Age_mar']\n",
        "\n",
        "#検証データに代入\n",
        "X_adult_test_fillna['Age_mar_knn'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_test.drop(drop, axis=1)),\n",
        "    index=X_adult_test.drop(drop, axis=1).index,\n",
        "    columns=X_adult_test.drop(drop, axis=1).columns)['Age_mar']\n",
        "\n",
        " ##################MNAR 埋める##################\n",
        "#使用しない特徴量のリスト特にターゲットエンコーディングした特徴量は除く\n",
        "drop = ['Education', 'Occupation', 'NativeCountry'\n",
        "        ] + ['Age', 'Age_mcar', 'Age_mar', 'fnlwgt']\n",
        "\n",
        "#KNNImputerインスタンス化\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "#訓練\n",
        "imputer.fit(X_adult_train.drop(drop, axis=1))\n",
        "#訓練データに代入\n",
        "X_adult_train_fillna['Age_mnar_knn'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_train.drop(drop, axis=1)),\n",
        "    index=X_adult_train.drop(drop, axis=1).index,\n",
        "    columns=X_adult_train.drop(drop, axis=1).columns)['Age_mnar']\n",
        "\n",
        "#検証データに代入\n",
        "X_adult_test_fillna['Age_mnar_knn'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_test.drop(drop, axis=1)),\n",
        "    index=X_adult_test.drop(drop, axis=1).index,\n",
        "    columns=X_adult_test.drop(drop, axis=1).columns)['Age_mnar']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZfcKkcqAxiD"
      },
      "source": [
        "#MARの代入前後の分布\n",
        "plt.figure(figsize=(14, 7))\n",
        "for i, col in enumerate(['Age_mar', 'Age_mar_reg', 'Age_mar_knn']):\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.hist(\n",
        "        X_adult_train_fillna['Age'],\n",
        "        alpha=0.7,\n",
        "        label='Complete Data',\n",
        "        bins=range(0, 100, 10))\n",
        "    plt.legend()\n",
        "    plt.hist(X_adult_train_fillna[col], alpha=0.7, bins=range(0, 100, 10))\n",
        "    plt.grid()\n",
        "    plt.title(col)\n",
        "    plt.xticks([0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvds6EE3PHON"
      },
      "source": [
        "### 2-6-4-3 多重代入法\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV19mqsgBGCk"
      },
      "source": [
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_iterative_imputer  \n",
        "# now you can import normally from sklearn.impute\n",
        "from sklearn.impute import IterativeImputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Vbmr-1BJ1D"
      },
      "source": [
        "##################MCAR 埋める##################\n",
        "#使用しない特徴量のリスト特にターゲットエンコーディングした特徴量は除く\n",
        "drop = ['Education', 'Occupation', 'NativeCountry'\n",
        "        ] + ['Age', 'Age_mar', 'Age_mnar', 'fnlwgt']\n",
        "\n",
        "#IterativeImputerインスタンス化\n",
        "imputer = IterativeImputer(max_iter=5, sample_posterior=True, random_state=123)\n",
        "\n",
        "#訓練\n",
        "imputer.fit(X_adult_train.drop(drop, axis=1))\n",
        "#訓練データに代入\n",
        "X_adult_train_fillna['Age_mcar_itr'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_train.drop(drop, axis=1)),\n",
        "    index=X_adult_train.drop(drop, axis=1).index,\n",
        "    columns=X_adult_train.drop(drop, axis=1).columns)['Age_mcar']\n",
        "\n",
        "#検証データに代入\n",
        "X_adult_test_fillna['Age_mcar_itr'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_test.drop(drop, axis=1)),\n",
        "    index=X_adult_test.drop(drop, axis=1).index,\n",
        "    columns=X_adult_test.drop(drop, axis=1).columns)['Age_mcar']\n",
        "\n",
        "##################MAR 埋める##################\n",
        "#使用しない特徴量のリスト特にターゲットエンコーディングした特徴量は除く\n",
        "drop = ['Education', 'Occupation', 'NativeCountry'\n",
        "        ] + ['Age', 'Age_mcar', 'Age_mnar', 'fnlwgt']\n",
        "\n",
        "#IterativeImputerインスタンス化\n",
        "imputer = IterativeImputer(max_iter=5, sample_posterior=True, random_state=123)\n",
        "#訓練\n",
        "imputer.fit(X_adult_train.drop(drop, axis=1))\n",
        "#訓練データに代入\n",
        "X_adult_train_fillna['Age_mar_itr'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_train.drop(drop, axis=1)),\n",
        "    index=X_adult_train.drop(drop, axis=1).index,\n",
        "    columns=X_adult_train.drop(drop, axis=1).columns)['Age_mar']\n",
        "\n",
        "#検証データに代入\n",
        "X_adult_test_fillna['Age_mar_itr'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_test.drop(drop, axis=1)),\n",
        "    index=X_adult_test.drop(drop, axis=1).index,\n",
        "    columns=X_adult_test.drop(drop, axis=1).columns)['Age_mar']\n",
        "\n",
        "##################MNAR 埋める##################\n",
        "#使用しない特徴量のリスト特にターゲットエンコーディングした特徴量は除く\n",
        "drop = ['Education', 'Occupation', 'NativeCountry'\n",
        "        ] + ['Age', 'Age_mcar', 'Age_mar', 'fnlwgt']\n",
        "\n",
        "#IterativeImputerインスタンス化\n",
        "imputer = IterativeImputer(max_iter=5, sample_posterior=True, random_state=123)\n",
        "#訓練\n",
        "imputer.fit(X_adult_train.drop(drop, axis=1))\n",
        "\n",
        "#訓練データに代入\n",
        "X_adult_train_fillna['Age_mnar_itr'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_train.drop(drop, axis=1)),\n",
        "    index=X_adult_train.drop(drop, axis=1).index,\n",
        "    columns=X_adult_train.drop(drop, axis=1).columns)['Age_mnar']\n",
        "\n",
        "#検証データに代入\n",
        "X_adult_test_fillna['Age_mnar_itr'] = pd.DataFrame(\n",
        "    imputer.transform(X_adult_test.drop(drop, axis=1)),\n",
        "    index=X_adult_test.drop(drop, axis=1).index,\n",
        "    columns=X_adult_test.drop(drop, axis=1).columns)['Age_mnar']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhxwqqefBLg7"
      },
      "source": [
        "#MARの代入前後の分布\n",
        "plt.figure(figsize=(14, 7))\n",
        "for i, col in enumerate(['Age_mar', 'Age_mar_itr']):\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.hist(\n",
        "        X_adult_train_fillna['Age'],\n",
        "        alpha=0.7,\n",
        "        label='Complete Data',\n",
        "        bins=range(0, 100, 10))\n",
        "    plt.legend()\n",
        "    plt.hist(X_adult_train_fillna[col], alpha=0.7, bins=range(0, 100, 10))\n",
        "    plt.grid()\n",
        "    plt.title(col)\n",
        "    plt.xticks([0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wvEAb1VPMbx"
      },
      "source": [
        "#### 2-6-4-4 数値代入法の選び方"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlBhvZQZBfy1"
      },
      "source": [
        "#MCARの代入法ごとのモデル精度比較\n",
        "#精度を格納するリスト\n",
        "l_tr = []\n",
        "l_te = []\n",
        "for age in [\n",
        "        'Age'\n",
        "] + [col for col in X_adult_train_fillna.columns if col.find('Age_mar_') > -1]:\n",
        "    #予測に必要な特徴量 'fnlwgt'は重み変数のため除外\n",
        "    var = [\n",
        "        col for col in X_adult_train.columns\n",
        "        if col.find('Age') == -1 and col.find('fnlwgt') == -1\n",
        "    ] + [age]\n",
        "    print(age, var)\n",
        "    #ロジスティック回帰インスタンス化\n",
        "    reg = LogisticRegression(solver='newton-cg')\n",
        "    #モデル学習\n",
        "    reg.fit(X_adult_train_fillna[var], y_adult_train)\n",
        "    #訓練データでの精度検証\n",
        "    l_tr.append(\n",
        "        accuracy_score(y_adult_train, reg.predict(X_adult_train_fillna[var])))\n",
        "    #検証データでの精度検証\n",
        "    l_te.append(\n",
        "        accuracy_score(y_adult_test, reg.predict(X_adult_test_fillna[var])))\n",
        "    \n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(\n",
        "    ['Age'] +\n",
        "    [col for col in X_adult_train_fillna.columns if col.find('Age_mar_') >-1],\n",
        "    l_tr,\n",
        "    label='Train')\n",
        "plt.plot(l_te, label='Test')\n",
        "plt.legend()\n",
        "plt.title('Impute MCAR')\n",
        "plt.ylim(0.845,0.855)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxaUyaw2B4W8"
      },
      "source": [
        "## 2-6-5 欠損カテゴリを新たに作成する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXKAk9cDBj4z"
      },
      "source": [
        "#架空の欠損データ生成\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import *\n",
        "seed(100)\n",
        "df_adult = pd.read_csv('adult.data', header=None)\n",
        "#変数名付与\n",
        "df_adult.columns = [\n",
        "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\", \"MaritalStatus\",\n",
        "    \"Occupation\", \"Relationship\", \"Race\", \"Gender\", \"CapitalGain\",\n",
        "    \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
        "]\n",
        "\n",
        "#Raceで欠損を作成する\n",
        "#全体の欠損率が20%、女性の欠損率が30%となるように設定\n",
        "p = 0.2\n",
        "p_f = 0.3\n",
        "p_m = (round(len(df_adult) * p) - df_adult.Gender.value_counts()[1] * p_f\n",
        "       ) / df_adult.Gender.value_counts()[0]\n",
        "\n",
        "#男性\n",
        "ix = df_adult['Gender'] == ' Male'\n",
        "seed(200)\n",
        "x = pd.Series(np.random.uniform(0.0, 1.0, len(df_adult)))\n",
        "x.index = df_adult.index\n",
        "df_adult['Race_mar'] = np.where((x < p_m) & (ix), np.nan, df_adult['Race'])\n",
        "\n",
        "#女性\n",
        "ix = df_adult['Gender'] == ' Male'\n",
        "seed(300)\n",
        "x = pd.Series(np.random.uniform(0.0, 1.0, len(df_adult)))\n",
        "x.index = df_adult.index\n",
        "df_adult['Race_mar'] = np.where((x < p_f) & (~ix), np.nan,\n",
        "                                df_adult['Race_mar'])\n",
        "\n",
        "#欠損を適当なカテゴリ名（\"Missing\")という文字列で埋める\n",
        "df_adult['Race_mar'].fillna('Missing', inplace=True)\n",
        "#集計\n",
        "print(df_adult['Race_mar'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQRiSpZsBmvw"
      },
      "source": [
        "#One-Hotエンコーディング インスタンス化\n",
        "encoder = ce.OneHotEncoder(cols=['Race_mar'], use_cat_names=True)\n",
        "enc = encoder.fit(df_adult)\n",
        "df_adult = enc.transform(df_adult)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FykYoA-vDqpY"
      },
      "source": [
        "# Chapter2-7 データスケーリング\n",
        "\n",
        "※サポートサイトから2章用のデータをダウンロードし、「UCI_Credit_Card.csv」をセッションストレージ（P.312）にアップして進めてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cpPz0ZKDtK3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "#preprosess モジュールのインポート\n",
        "from sklearn import preprocessing\n",
        "#データ分割用\n",
        "from sklearn.model_selection import train_test_split\n",
        "#ロジスティック回帰モデル作成のため\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "#可視化のため\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#データ読み込み\n",
        "df = pd.read_csv('UCI_Credit_Card.csv')\n",
        "#要約確認\n",
        "df.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSEmep3CEIFb"
      },
      "source": [
        "#train test データ分離\n",
        "X = df.drop(\n",
        "    [\n",
        "        'ID', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE',\n",
        "        'default.payment.next.month'\n",
        "    ],\n",
        "    axis=1)\n",
        "y = df['default.payment.next.month']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBsoApCgEPzG"
      },
      "source": [
        "## 2-7-1 Min-Max法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7SwX7VfELGQ"
      },
      "source": [
        "#MinMaxScalerのインスタンス化\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "# train\n",
        "X_train_min_max = min_max_scaler.fit_transform(X_train)\n",
        "# test trainを基準にしないとリークしてしまう\n",
        "X_test_min_max = min_max_scaler.transform(X_test)\n",
        "\n",
        "#分布描画\n",
        "fontdic = {'size': 20}\n",
        "plt.figure(figsize=(14, 7))\n",
        "#変換前\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(X_train['BILL_AMT1'])\n",
        "plt.title('Before', fontdict=fontdic)\n",
        "plt.grid()\n",
        "#変換後\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(X_train_min_max[:, 8], color='red')\n",
        "plt.title('After', fontdict=fontdic)\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D28aH3HfEaQ4"
      },
      "source": [
        "## 2-7-2 Zスコア標準化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgvWQDtwEM8g"
      },
      "source": [
        "#zスコア変換\n",
        "standard_scaler = preprocessing.StandardScaler()  \n",
        "# train\n",
        "X_train_standard = standard_scaler.fit_transform(X_train)\n",
        "# test trainを基準にしないとリークしてしまう\n",
        "X_test_standard = standard_scaler.transform(X_test)\n",
        "\n",
        "#分布描画\n",
        "fontdic = {'size': 20}\n",
        "plt.figure(figsize=(14, 7))\n",
        "#変換前\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(X_train['BILL_AMT1'])\n",
        "plt.title('Before', fontdict=fontdic)\n",
        "plt.grid()\n",
        "#変換後\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(X_train_standard[:, 8], color='red')\n",
        "plt.title('After', fontdict=fontdic)\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwvhnPFsEe84"
      },
      "source": [
        "## 2-7-3 10進スケールの正規化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DZhJUEaEXLY"
      },
      "source": [
        "#10進変換\n",
        "#変換用の関数作成\n",
        "def decimal_fit_trans(x):\n",
        "    #絶対値の最大値をカラムごとに取得\n",
        "    temp = np.nanmax(np.abs(x.values),axis=0)\n",
        "    arr = np.array([])\n",
        "    #カラムごとに除する定数を取得\n",
        "    for t in temp:\n",
        "        i = 0\n",
        "        while t/10**(i) > 1:\n",
        "            i += 1\n",
        "        arr = np.r_[arr,1/10**(i)]\n",
        "    return  (arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SYn5e_FEknw"
      },
      "source": [
        "#train\n",
        "X_train_decimal = X_train*decimal_fit_trans(X_train)\n",
        "#test  \n",
        "X_test_decimal = X_test*decimal_fit_trans(X_train)\n",
        "#分布描画\n",
        "fontdic = {'size':20}\n",
        "plt.figure(figsize=(14,7))\n",
        "#変換前\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(X_train['BILL_AMT1'])\n",
        "plt.title('Before',fontdict=fontdic)\n",
        "plt.grid()\n",
        "#変換後\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(X_train_decimal['BILL_AMT1'],color='red')\n",
        "plt.title('After',fontdict=fontdic)\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6lcrxXmEtVo"
      },
      "source": [
        "## 2-7-4 スケーリング手法比較"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb0dV153ErNI"
      },
      "source": [
        "#変換後比較\n",
        "plt.figure(figsize=(14, 10))\n",
        "for i, col in enumerate(X_train.columns):\n",
        "    plt.subplot(5, 4, i + 1)\n",
        "    plt.hist(\n",
        "        pd.DataFrame(X_train_min_max, columns=X_train.columns)[col],\n",
        "        color='blue',\n",
        "        alpha=0.5,\n",
        "        label='Min-Max')\n",
        "    plt.hist(\n",
        "        pd.DataFrame(X_train_standard, columns=X_train.columns)[col],\n",
        "        color='green',\n",
        "        alpha=0.5,\n",
        "        label='Standard')\n",
        "    plt.hist(X_train_decimal[col], color='red', alpha=0.5, label='Decimal')\n",
        "    plt.title(col)\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3V7FC80ExVh"
      },
      "source": [
        "#モデルの生成\n",
        "clf = LogisticRegression()\n",
        "# 精度を格納するリスト\n",
        "l = []\n",
        "# 学習\n",
        "#スケーリングなし\n",
        "clf.fit(X_train, y_train)\n",
        "l.append(accuracy_score(y_test, clf.predict(X_test)))\n",
        "#min_max変換\n",
        "clf.fit(X_train_min_max, y_train)\n",
        "l.append(accuracy_score(y_test, clf.predict(X_test_min_max)))\n",
        "#zスコア変換\n",
        "clf.fit(X_train_standard, y_train)\n",
        "l.append(accuracy_score(y_test, clf.predict(X_test_standard)))\n",
        "#10進変換\n",
        "clf.fit(X_train_decimal, y_train)\n",
        "l.append(accuracy_score(y_test, clf.predict(X_test_decimal)))\n",
        "# 精度一覧\n",
        "print(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJwYwf1DE30J"
      },
      "source": [
        "# Chapter2-8 データ変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYMEUintFIg0"
      },
      "source": [
        "## 2-8-2 二次型変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crMpV-DoE3Xp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#人工データを作成\n",
        "from sklearn.datasets import make_circles\n",
        "X, y = make_circles(noise=0.02, random_state=0)  #ラベル付き円を作成\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='winter')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGRz1OthFL-1"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#x軸y軸を説明変数としてロジスティック回帰を適用\n",
        "clf = LogisticRegression()\n",
        "X_train = X\n",
        "y_train = y\n",
        "clf.fit(X_train, y_train)\n",
        "accuracy_score(y_train, clf.predict(X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ywhdcuoFO2S"
      },
      "source": [
        "#2次変換\n",
        "#モデルの生成\n",
        "clf_q = LogisticRegression()\n",
        "Z = (X[:, 0]**(2) + X[:, 1]**(2)).reshape(-1, 1)\n",
        "X_train = Z\n",
        "y_train = y\n",
        "clf_q.fit(X_train, y_train)\n",
        "accuracy_score(y_train, clf_q.predict(X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CSVNA5TFRHC"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "#通常の方法\n",
        "x_=np.linspace(-1,1,100)\n",
        "plt.scatter(X[:,0],X[:,1],c=y,cmap='winter')\n",
        "#log(p/(1-p)=1/2となる線を描画する\n",
        "plt.plot(x_,(-1*(clf.coef_[:,0]*x_)-clf.intercept_)/clf.coef_[:,1])\n",
        "plt.ylim([-1,1])\n",
        "\n",
        "#2次変換\n",
        "theta = np.arange(0,2*np.pi+1,0.1)\n",
        "xlist=[];ylist=[]\n",
        "r =  ((clf_q.intercept_/(-1*clf_q.coef_))**(1/2))[0,0] #半径\n",
        "for i in theta:\n",
        "\txlist.append(r*np.cos(i))\n",
        "\tylist.append(r*np.sin(i))\n",
        "plt.plot(xlist,ylist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-7TongCFYtV"
      },
      "source": [
        "## 2-8-3 変換の非多項式近似"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqEQSesyFW0q"
      },
      "source": [
        "#三角形の合同問題\n",
        "from pandas import DataFrame\n",
        "#例として合同な三角形を考えるため描画ライブラリを読み込む\n",
        "\n",
        "#乱数設定\n",
        "np.random.seed(1)\n",
        "ran_l1 = list(np.random.rand(10) * 5)\n",
        "np.random.seed(2)\n",
        "ran_l2 = list(np.random.rand(10))\n",
        "\n",
        "#三角形の座標データを作成\n",
        "base1 = np.array([0, 1, -1, 0, 1, 0])\n",
        "base2 = np.array([0, 0, 1, 0, 0, np.sqrt(3)])\n",
        "data = np.vstack([base1 - i\n",
        "                  for i in ran_l1[0:5]] + [base2 - i for i in ran_l1[5:]])\n",
        "l = []\n",
        "for i, j in zip(data, ran_l2):\n",
        "    theta = (2 * j) * np.pi\n",
        "    l.append(\n",
        "        np.dot(\n",
        "            np.array([[np.cos(theta), -np.sin(theta)],\n",
        "                      [np.sin(theta), np.cos(theta)]]),\n",
        "            i.reshape(3, 2).T).T.reshape(-1))\n",
        "\n",
        "data = np.vstack(l)\n",
        "\n",
        "df_data = DataFrame(data, columns=['x1', 'y1', 'x2', 'y2', 'x3', 'y3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OniAQxZaFdS1"
      },
      "source": [
        "print (df_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhSQ734AFfjp"
      },
      "source": [
        "#描画する\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "for k, i in enumerate(data):\n",
        "  print(i, k)\n",
        "  if k < 5:\n",
        "      tri = plt.Polygon(\n",
        "          ((i[0], i[1]), (i[2], i[3]), (i[4], i[5])), fc=\"blue\")\n",
        "      ax.add_patch(tri)\n",
        "  else:\n",
        "      tri = plt.Polygon(((i[0], i[1]), (i[2], i[3]), (i[4], i[5])), fc=\"red\")\n",
        "      ax.add_patch(tri)\n",
        "plt.xlim(-7, 7)\n",
        "plt.ylim(-7, 7)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW6WKtvrFodr"
      },
      "source": [
        "## 2-8-4 ランク変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWUrFpm0FhjC"
      },
      "source": [
        "#人工的にデータを作成\n",
        "#y ~ N(3x+1,0.2) に従う(x in [0,1])\n",
        "np.random.seed(seed=1)\n",
        "x = np.random.rand(100)\n",
        "y = np.random.normal(3 * x + 1, 0.2)\n",
        "#xの外れ値を作成\n",
        "x = np.where(x == max(x), 3, x)\n",
        "plt.scatter(x=x, y=y)\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rium0ciwFsQS"
      },
      "source": [
        "#ランク算出のためのライブラリインポート\n",
        "from scipy.stats import rankdata\n",
        "#正規分布の累積分布関数の逆関数を計算するためにインポート\n",
        "from scipy.stats import norm\n",
        "#ランク変換関数定義\n",
        "def rank_fit_transform(x):\n",
        "  return (norm.ppf((rankdata(x) - (3 / 8)) / (len(x) + (1 / 4))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKX3yyIEGELs"
      },
      "source": [
        "#線形回帰モデルの準備\n",
        "from sklearn import linear_model\n",
        "\n",
        "#ランク変換前\n",
        "clf = linear_model.LinearRegression()\n",
        "X = x.reshape(-1, 1)\n",
        "y = y\n",
        "clf.fit(X, y)\n",
        "clf.score(X, y)\n",
        "\n",
        "#ランク変換後\n",
        "clf_r = linear_model.LinearRegression()\n",
        "X_r = rank_fit_transform(x).reshape(-1, 1)\n",
        "y = y\n",
        "clf_r.fit(X_r, y)\n",
        "clf_r.score(X_r, y)\n",
        "#決定係数\n",
        "print(\"変換前_{:.5g}\".format(clf.score(X, y)), \"変換後_{:.5g}\".format(\n",
        "\tclf_r.score(X_r, y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxu3fLr3GFyr"
      },
      "source": [
        "#直線当てはめを描画\n",
        "plt.figure(figsize=(14, 7))\n",
        "#変換なし\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(X, y)\n",
        "plt.scatter(X, clf.predict(X), s=5)\n",
        "plt.grid()\n",
        "plt.title('Before')\n",
        "#ランク変換後\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(X_r, y)\n",
        "plt.scatter(X_r, clf_r.predict(X_r), s=5)\n",
        "plt.grid()\n",
        "plt.title('After')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On6oqrzOGK6o"
      },
      "source": [
        "## 2-8-5 Box-Cox変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RkmMQP2GImu"
      },
      "source": [
        "#必要なライブラリ読み込む\n",
        "from scipy import stats  #boxcox変換のため\n",
        "from sklearn import linear_model  #線形回帰モデル\n",
        "from sklearn.model_selection import train_test_split  #訓練データ分割\n",
        "#UCI よりレンタル自転車のデータを読み込む\n",
        "df = pd.read_csv('hour.csv')\n",
        "#描画準備\n",
        "plt.figure(figsize=(14, 7))\n",
        "#cntの変換前ヒストグラム\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['cnt'])\n",
        "plt.title('Before')\n",
        "plt.grid()\n",
        "#box-cox変換後の分布\n",
        "plt.subplot(1, 2, 2)\n",
        "bc, _ = stats.boxcox(df['cnt'])\n",
        "plt.hist(bc)\n",
        "plt.title('After')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThSGyc4jGPwb"
      },
      "source": [
        "#データを訓練データとテストデータに分離\n",
        "X = df['temp'].values\n",
        "y = df['cnt'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "\tX, y, test_size=0.2, random_state=0)\n",
        "\n",
        "#変換\n",
        "y_train_bc, lambd = stats.boxcox(y_train)\n",
        "\n",
        "#変換前回帰\n",
        "clf = linear_model.LinearRegression()\n",
        "clf.fit(X_train.reshape(-1, 1), y_train.reshape(-1, 1))\n",
        "\n",
        "#変換後回帰\n",
        "clf_bc = linear_model.LinearRegression()\n",
        "clf_bc.fit(X_train.reshape(-1, 1), y_train_bc.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5cPCYVMGSLs"
      },
      "source": [
        "#残差プロット\n",
        "#比較用y=0の線\n",
        "x = np.arange(0, 20)\n",
        "y = 0 * x\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "#変換前\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(\n",
        "    clf_bc.predict(X_train.reshape(-1, 1)),\n",
        "    y_train.reshape(-1, 1) - clf.predict(X_train.reshape(-1, 1)))\n",
        "plt.plot(x, y, color='red')\n",
        "plt.title('Before')\n",
        "#変換後\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(\n",
        "    clf_bc.predict(X_train.reshape(-1, 1)),\n",
        "    y_train_bc.reshape(-1, 1) - clf_bc.predict(X_train.reshape(-1, 1)))\n",
        "plt.plot(x, y, color='red')\n",
        "plt.title('After')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYRz8HEAGYFb"
      },
      "source": [
        "# Chapter2-9 次元削減法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_PWnCITGV3U"
      },
      "source": [
        "# 日本語フォントの設定★\n",
        "%%bash\n",
        "apt-get install -y fonts-ipafont-gothic > /dev/null\n",
        "cachedir=$(python -c 'import matplotlib as m; print(m.get_cachedir())')\n",
        "rm -f $cachedir/fontlist-v300.json\n",
        "pip install japanize-matplotlib > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3qCUpJvnDFR"
      },
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot\n",
        "import japanize_matplotlib\n",
        "matplotlib.rc('font', family=\"IPAexGothic\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JISC8ZhJPv9C"
      },
      "source": [
        "###  2-9-1 次元の呪い"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvOXy8vIKD4G"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#球面集中問題\n",
        "def calc_volume(e, D):\n",
        "\treturn 1 - (1 - e)**D\n",
        "\n",
        "vol_list = []\n",
        "e = 0.01\n",
        "for i in range(1, 300):\n",
        "\tvol_list.append(calc_volume(e, i))\n",
        "\n",
        "#図示する\n",
        "plt.plot(vol_list)\n",
        "plt.xlabel('次元')\n",
        "plt.ylabel('球の体積比')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wOvrdrLKJ6I"
      },
      "source": [
        "## 2-9-2 主成分分析（PCA）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY-xY05sKFYj"
      },
      "source": [
        "from sklearn.decomposition import PCA  #主成分分析\n",
        "#ESTAT 県民総生産 (2015)データ 読み込む\n",
        "df = pd.read_csv('FEI_PREF_2015.csv').set_index('地域')\n",
        "#データ中身確認\n",
        "df.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZdTXdoDKHak"
      },
      "source": [
        "#PCA\n",
        "pca = PCA()\n",
        "pca.fit(df[['情報通信業', '金融・保険業']])\n",
        "#図示する\n",
        "fig = plt.figure(figsize=(16, 7))\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax1.scatter(df['情報通信業'], df['金融・保険業'])\n",
        "ax2.scatter(df['情報通信業'], df['金融・保険業'])\n",
        "#第一主成分の軸を図示\n",
        "y = (pca.components_[0][1] / pca.components_[0][0]) * (\n",
        "\tnp.linspace(0, 0.15, 100) - np.mean(df['情報通信業'])) + np.mean(df['金融・保険業'])\n",
        "ax2.plot(np.linspace(0, 0.15, 100), y, color='red')\n",
        "#第二主成分の軸を図示\n",
        "y = (pca.components_[1][1] / pca.components_[1][0]) * (\n",
        "\tnp.linspace(0, 0.15, 100) - np.mean(df['情報通信業'])) + np.mean(df['金融・保険業'])\n",
        "ax2.plot(np.linspace(0, 0.15, 100), y, color='red')\n",
        "#中心を赤でplot\n",
        "ax2.scatter(np.mean(df['情報通信業']), np.mean(df['金融・保険業']), color='red')\n",
        "#目盛の範囲を調整\n",
        "ax1.set_ylim(-0.05, 0.1)\n",
        "ax2.set_ylim(-0.05, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsCxjMnfKPAl"
      },
      "source": [
        "#新しい直交座標系でプロット\n",
        "fig = plt.figure(figsize=(14, 7))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "#元の系列\n",
        "ax.scatter(\n",
        "\tpca.transform(df[['情報通信業', '金融・保険業']])[:, 0],\n",
        "\tpca.transform(df[['情報通信業', '金融・保険業']])[:, 1])\n",
        "#第一主成分の座標\n",
        "x = pca.transform(df[['情報通信業', '金融・保険業']])[:, 0]\n",
        "y = x * 0\n",
        "ax.scatter(x, y)\n",
        "ax.plot(\n",
        "\tnp.linspace(-0.02, 0.1, 100),\n",
        "\tnp.linspace(-0.02, 0.02, 100) * 0,\n",
        "\tcolor='red')\n",
        "#第二主成分の座標\n",
        "y = pca.transform(df[['情報通信業', '金融・保険業']])[:, 1]\n",
        "x = y * 0\n",
        "ax.scatter(x, y)\n",
        "ax.plot(\n",
        "\tnp.linspace(-0.02, 0.1, 100) * 0,\n",
        "\tnp.linspace(-0.02, 0.02, 100),\n",
        "\tcolor='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOUe_03JKR-E"
      },
      "source": [
        "#寄与度\n",
        "print (pca.explained_variance_ratio_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDKr7iYHKWYk"
      },
      "source": [
        "## 2-9-3 因子分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr7hse7EKYAO"
      },
      "source": [
        "!pip install factor-analyzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1EjrCB8KZ6M"
      },
      "source": [
        "#因子分析用のライブラリを読み込む\n",
        "from factor_analyzer import FactorAnalyzer\n",
        "import matplotlib.pyplot as plt #可視化のため\n",
        "import numpy.linalg as LA #固有値計算のため\n",
        "\n",
        "#ESTAT 県民総生産 (2015)データ 読み込む\n",
        "df = pd.read_csv('FEI_PREF_2015.csv').set_index('地域')\n",
        "U = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORdP--8yKdPn"
      },
      "source": [
        "#固有値の大きさ\n",
        "ev, _ = LA.eig(U.corr())  #相関係数行列の固有値\n",
        "plt.bar(np.arange(len(ev)), ev)  #固有値プロット\n",
        "plt.plot([1] * 20, color='red')  #比較用のy=1の線をプロット"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E7WXnjUKf9V"
      },
      "source": [
        "#因子分析のインスタンス作成\n",
        "fa = FactorAnalyzer(rotation=None, n_factors=5)  #回転させない\n",
        "#モデリング\n",
        "fa.fit(U)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4CHny4EP9j4"
      },
      "source": [
        "#因子負荷量 プロット\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "#ax = []\n",
        "for i in np.arange(5):\n",
        "   ax = fig.add_subplot(3,2,i+1)\n",
        "   plt.title('第'+str(i+1)+'因子負荷量')\n",
        "   ax.bar([i[0:2] for i in U.columns],fa.loadings_[:,i]) #ラベルの先頭2文字のみ出力"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqsD8aH7Kpth"
      },
      "source": [
        "## 2-9-4 多次元尺度構成法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEEJ8OfsKmKy"
      },
      "source": [
        "#多次元尺度構成法ライブラリ読み込む\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.datasets import load_wine\n",
        "import matplotlib.pyplot as plt\n",
        "#ワインデータ読み込み\n",
        "data = load_wine()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "#MDSインスタンス作成しfitさせる\n",
        "embedding = MDS(\n",
        "\tn_components=2, metric=True,\n",
        "\trandom_state=1)  #metricのデフォルトはTrue 間隔尺度であるため計量MDSを実行\n",
        "X_mds = embedding.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW6CEPA7Ku5e"
      },
      "source": [
        "#次元ごとのストレス値\n",
        "l = []\n",
        "for i in np.arange(len(X.columns)):\n",
        "\tembedding = MDS(\n",
        "    \tn_components=i + 1, metric=True,\n",
        "    \trandom_state=1)  #metricのデフォルトはTrue 間隔尺度であるため計量MDSを実行\n",
        "\tX_mds = embedding.fit_transform(X)\n",
        "\tl.append(embedding.stress_)\n",
        "\n",
        "plt.plot(np.arange(len(X.columns)) + 1, l, color='red')\n",
        "plt.xlabel('次元数')\n",
        "plt.ylabel('ストレス値')\n",
        "plt.xlim(0, 13)\n",
        "plt.xticks(np.arange(len(X.columns)) + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV3ZS3hFKwVv"
      },
      "source": [
        "#2次元に配置する\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "X_mds[y == 0, 0]\n",
        "for i, j, k in zip(np.arange(3), ['blue', 'red', 'green'], ['^', 's', 'o']):\n",
        "\tax.scatter(X_mds[y == i, 0], X_mds[y == i, 1], color=j, marker=k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnMez2dLK0l_"
      },
      "source": [
        "## 2-9-5 局所線形埋め込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmZEl1Y4Kyx2"
      },
      "source": [
        "#スパイラルデータ作成\n",
        "x = np.array([[\n",
        "\tnp.exp(-0.2 * (-2 * np.pi * (i / 360))) * np.cos(-2 * np.pi * (i / 360))\n",
        "\tfor i in np.arange(0, 3000, 10)\n",
        "], [\n",
        "\tnp.exp(-0.2 * (-2 * np.pi * (i / 360))) * np.sin(-2 * np.pi * (i / 360))\n",
        "\tfor i in np.arange(0, 3000, 10)\n",
        "]]).T\n",
        "#図示する\n",
        "fig = plt.figure(figsize=(16, 7))\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax1.scatter(\n",
        "\tnp.arange(0, 3000, 10),\n",
        "\tnp.arange(0, 3000, 10) * 0,\n",
        "\tc=np.arange(0, 3000, 10),\n",
        "\tcmap=plt.cm.Spectral,\n",
        "\ts=5)\n",
        "ax2.scatter(\n",
        "\tx[:, 0], x[:, 1], c=np.arange(0, 3000, 10), cmap=plt.cm.Spectral, s=20)\n",
        "ax2.set_ylim(-40000, 30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8AoAbULK5Vn"
      },
      "source": [
        "#主成分分析をしてみる\n",
        "from sklearn.decomposition import PCA  #主成分分析\n",
        "pca = PCA()\n",
        "pca.fit(x)\n",
        "#図示する\n",
        "fig = plt.figure(figsize=(16, 7))\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax1.scatter(x[:, 0], x[:, 1], c=np.arange(0, 3000, 10), cmap=plt.cm.Spectral)\n",
        "#第一主成分の軸を図示\n",
        "y = (pca.components_[0][1] / pca.components_[0][0]) * (\n",
        "\tnp.linspace(-10000, 10000, 100) - np.mean(x[:, 0])) + np.mean(x[:, 1])\n",
        "ax1.plot(np.linspace(-5000, 5000, 100), y, color='red')\n",
        "ax1.set_ylim(-40000, 30000)\n",
        "#第一主成分を1次元で表す\n",
        "ax2.scatter(\n",
        "\tpca.fit_transform(x)[:, 0],\n",
        "\tnp.arange(0, 3000, 10) * 0,\n",
        "\tc=np.arange(0, 3000, 10),\n",
        "\tcmap=plt.cm.Spectral)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sjwHurAK-be"
      },
      "source": [
        "#多様体学習ライブラリからLLEクラスをインポート\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "#インスタンス化\n",
        "embedding = LocallyLinearEmbedding(n_components=1,\n",
        "                               \trandom_state=1)  #1次元に対応する\n",
        "X_transformed = embedding.fit_transform(x)\n",
        "#1次元のカラーマップ\n",
        "fig = plt.figure(figsize=(16, 7))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.scatter(\n",
        "\tX_transformed,\n",
        "\tnp.arange(0, 3000, 10) * 0,\n",
        "\tc=np.arange(0, 3000, 10),\n",
        "\tcmap=plt.cm.Spectral)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyTbrmuSLUS5"
      },
      "source": [
        "#ワインデータ読み込み\n",
        "data = load_wine()\n",
        "embedding = LocallyLinearEmbedding(n_components=2, random_state=1)\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "X_transformed = embedding.fit_transform(X)\n",
        "#2次元に配置する\n",
        "fig = plt.figure(figsize=(7, 5))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "for i, j, k in zip(np.arange(3), ['blue', 'red', 'green'], ['^', 's', 'o']):\n",
        "\tax.scatter(\n",
        "    \tX_transformed[y == i, 0], X_transformed[y == i, 1], color=j, marker=k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2YQl45tLX6M"
      },
      "source": [
        "## 2-9-6 t-SNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI_3ci37QKHE"
      },
      "source": [
        "#### 2-9-6-2 t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPOY7hrOLWK3"
      },
      "source": [
        "# t-SNE\n",
        "from sklearn.manifold import TSNE\n",
        "#ワインデータ読み込み\n",
        "data = load_wine()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekGJt8K7Lc43"
      },
      "source": [
        "X_transformed = TSNE(\n",
        "\tn_components=2, perplexity=30, random_state=0).fit_transform(X)\n",
        "#2次元に配置する\n",
        "fig = plt.figure(figsize=(7, 5))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "for i, j, k in zip(np.arange(3), ['blue', 'red', 'green'], ['^', 's', 'o']):\n",
        "\tax.scatter(\n",
        "    \tX_transformed[y == i, 0], X_transformed[y == i, 1], color=j, marker=k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTgzs-ApLgah"
      },
      "source": [
        "# Chapter2-10 特徴量選択\n",
        "\n",
        "※サポートサイトから2章用のデータをダウンロードし、「adult.data」をセッションストレージ（P.312）にアップして進めてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2bkw3HIQPrj"
      },
      "source": [
        "### 2-10-1 特徴量選択の3手法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upm2ayJcLi1H"
      },
      "source": [
        "## ここで「You must restart the runtime in order to use newly installed versions.」というメッセージが出たら、「RESTART RUNTIME」ボタンをクリックしてランタイムを再起動してください。\n",
        "!pip uninstall scikit-learn\n",
        "!pip install scikit-learn==0.21.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAWnZFKWLqho"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnWjVs_YLrxP"
      },
      "source": [
        "#データをトレーニング・テストに分けるモジュール\n",
        "from sklearn.model_selection import train_test_split\n",
        "#ロジスティック回帰モデル\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#正答率算出\n",
        "from sklearn.metrics import accuracy_score\n",
        "#category encoder インポート\n",
        "import category_encoders as ce\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#データ 読み込み\n",
        "df_adult = pd.read_csv('adult.data', header=None)\n",
        "#変数名付与\n",
        "df_adult.columns = [\n",
        "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\", \"MaritalStatus\",\n",
        "    \"Occupation\", \"Relationship\", \"Race\", \"Gender\", \"CapitalGain\",\n",
        "    \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
        "]\n",
        "\n",
        "#ターゲット変数1/0エンコーディング\n",
        "df_adult['Income'] = (df_adult['Income'] == ' >50K').astype(int)\n",
        "#特徴量取得\n",
        "X_adult = df_adult.drop(['Income'], axis=1)\n",
        "#ターゲット変数を取得\n",
        "y_adult = df_adult['Income']\n",
        "#訓練・検証データを分離\n",
        "X_adult_train, X_adult_test, y_adult_train, y_adult_test = train_test_split(\n",
        "    X_adult, y_adult, test_size=0.2, random_state=1)\n",
        "\n",
        "#ターゲットエンコーダ インスタンス化\n",
        "encoder = ce.TargetEncoder(cols=['Education', 'Occupation', 'NativeCountry'])\n",
        "enc = encoder.fit(X_adult_train, y_adult_train)\n",
        "X_adult_train = enc.transform(X_adult_train)\n",
        "X_adult_test = enc.transform(X_adult_test)\n",
        "\n",
        "#One-Hotエンコーディング インスタンス化\n",
        "encoder = ce.OneHotEncoder(\n",
        "    cols=['WorkClass', 'MaritalStatus', 'Relationship', 'Race', 'Gender'],\n",
        "    use_cat_names=True)\n",
        "enc = encoder.fit(X_adult_train)\n",
        "X_adult_train = enc.transform(X_adult_train)\n",
        "X_adult_test = enc.transform(X_adult_test)\n",
        "\n",
        "#One-Hotエンコーディングで冗長になった変数を落とす\n",
        "drop_l = [\n",
        "    [col for col in X_adult_train.columns if col.find('WorkClass') >= 0][0], [\n",
        "        col for col in X_adult_train.columns if col.find('MaritalStatus') >= 0\n",
        "    ][0], [\n",
        "        col for col in X_adult_train.columns if col.find('Relationship') >= 0\n",
        "    ][0], [col for col in X_adult_train.columns if col.find('Race') >= 0][0],\n",
        "    [col for col in X_adult_train.columns if col.find('Gender') >= 0][0]\n",
        "]\n",
        "X_adult_train = X_adult_train.drop(drop_l, axis=1)\n",
        "X_adult_test = X_adult_test.drop(drop_l, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEIzP7JeLuPo"
      },
      "source": [
        "#すべての特徴量\n",
        "features_all = X_adult_train.columns\n",
        "print('特徴量 : {} '.format(features_all))\n",
        "#比較用として全ての特徴量でモデル作成\n",
        "#フルモデルと比較\n",
        "reg = LogisticRegression().fit(X_adult_train, y_adult_train)\n",
        "score_all = accuracy_score(y_adult_test, reg.predict(X_adult_test))\n",
        "print('訓練 : {} '.format(\n",
        "    accuracy_score(y_adult_train, reg.predict(X_adult_train))))\n",
        "print('検証 : {} '.format(\n",
        "    accuracy_score(y_adult_test, reg.predict(X_adult_test))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX7rUZazMEYS"
      },
      "source": [
        "## 2-10-2 Filter法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEks2CNbMCsI"
      },
      "source": [
        "#単変量Filterモジュール読み込む\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, f_classif, chi2\n",
        "#F値でfeature selection filter法\n",
        "tr_score = []  #訓練スコアを入れるリスト\n",
        "te_score = []  #検証スコアを入れるリスト\n",
        "features = []  #特徴量を入れるりスト\n",
        "#Kごとに精度評価\n",
        "for i in np.arange(len(X_adult_train.columns)):\n",
        "    sel = SelectKBest(f_classif, k=i + 1).fit(X_adult_train, y_adult_train)\n",
        "    X_train_sel = sel.transform(X_adult_train)\n",
        "    X_test_sel = sel.transform(X_adult_test)\n",
        "    reg = LogisticRegression().fit(X_train_sel, y_adult_train)\n",
        "    tr_score.append(accuracy_score(y_adult_train, reg.predict(X_train_sel)))\n",
        "    te_score.append(accuracy_score(y_adult_test, reg.predict(X_test_sel)))\n",
        "    features.append(X_adult_train.columns[sel.get_support()])\n",
        "\n",
        "#kごとに精度がどのように変わったか可視化する\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(np.arange(len(X_adult_train.columns)) + 1, tr_score, label='Train')\n",
        "plt.plot(np.arange(len(X_adult_train.columns)) + 1, te_score, label='Test')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('The Number of features')\n",
        "plt.xticks(np.arange(1, 1 + len(X_adult_train.columns)))\n",
        "plt.legend(fontsize=14)\n",
        "plt.grid()\n",
        "plt.title('Feature selection by using F value')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDlvCCxnMIUY"
      },
      "source": [
        "#訓練データの精度最大となるk\n",
        "print (tr_score.index(np.max(tr_score)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_caUc1jAMTYC"
      },
      "source": [
        "#訓練データで精度最大になる変数の数と組み合わせ\n",
        "features_sel_filter = features[tr_score.index(np.max(tr_score))]\n",
        "print ('特徴量 : {} '.format(features_sel_filter))\n",
        "print ('訓練 : {} '.format((tr_score[tr_score.index(np.max(tr_score))])))\n",
        "print ('検証 : {} '.format((te_score[tr_score.index(np.max(tr_score))])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwaexE2VMWIw"
      },
      "source": [
        "## 2-10-3 Wrapper法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zJeCxgCMU4w"
      },
      "source": [
        "!pip install -U mlxtend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Rvb5DwMZ2R"
      },
      "source": [
        "#wrapper法実行モジュール読み込む\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brqdy0AbU6K0"
      },
      "source": [
        "####2-10-3-1 Sequence Forward Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r_BBVkUMcES"
      },
      "source": [
        "#SFSインスタンス化\n",
        "sfs = SFS(LogisticRegression(),  #利用するモデル\n",
        "           k_features=(1,33), #特徴量の数 1-33個の間でCVスコアベストを探す\n",
        "           forward=True, #フォワード型\n",
        "           floating=False, #フローティングの有無\n",
        "           verbose=2,\n",
        "           scoring='accuracy',#精度指標\n",
        "           cv=5,\n",
        "          n_jobs=-1)\n",
        "\n",
        "sfs = sfs.fit(X_adult_train, y_adult_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mk6asNHMezJ"
      },
      "source": [
        "fig1 = plot_sfs(sfs.get_metric_dict(), kind='std_dev', figsize=(14, 7))\n",
        "plt.title('Sequence Forward Generation (w. StdDev)')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe-id9efMgt7"
      },
      "source": [
        "#選ばれた特徴量のサブセットでモデルを作成\n",
        "features_sel_wrapper_sfg = list(sfs.k_feature_names_)\n",
        "reg = LogisticRegression().fit(X_adult_train[features_sel_wrapper_sfg],\n",
        "                               y_adult_train)\n",
        "print('特徴量 : {} '.format(features_sel_wrapper_sfg))\n",
        "print('訓練 : {} '.format(\n",
        "    accuracy_score(y_adult_train,\n",
        "                   reg.predict(X_adult_train[features_sel_wrapper_sfg]))))\n",
        "print('検証 : {} '.format(\n",
        "    accuracy_score(y_adult_test,\n",
        "                   reg.predict(X_adult_test[features_sel_wrapper_sfg]))))\n",
        "score_sel_wrapper_sfg = accuracy_score(\n",
        "    y_adult_test, reg.predict(X_adult_test[features_sel_wrapper_sfg]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gu7L67IQeks"
      },
      "source": [
        "#### 2-10-3-2 Sequential Backward Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZeMOAEjMjWR"
      },
      "source": [
        "#SFSインスタンス化\n",
        "sbs = SFS(LogisticRegression(),  #利用するモデル\n",
        "           k_features=(1,33), #特徴量の数 1-33個の間でCVスコアベストを探す\n",
        "           forward=False, #バックワード型\n",
        "           floating=False, #フローティングの有無\n",
        "           verbose=2,\n",
        "           scoring='accuracy',#精度指標\n",
        "           cv=5,\n",
        "          n_jobs=-1)\n",
        "\n",
        "sbs = sbs.fit(X_adult_train, y_adult_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v5yKTIsMmdB"
      },
      "source": [
        "fig1 = plot_sfs(sbs.get_metric_dict(), kind='std_dev', figsize=(14, 7))\n",
        "plt.title('Sequence Backward Generation (w. StdDev)')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7jXWxCuMpFs"
      },
      "source": [
        "#選ばれた特徴量のサブセットでモデルを作成\n",
        "features_sel_wrapper_sbg = list(sbs.k_feature_names_)\n",
        "reg = LogisticRegression().fit(X_adult_train[features_sel_wrapper_sbg],\n",
        "                               y_adult_train)\n",
        "print('特徴量 : {} '.format(features_sel_wrapper_sbg))\n",
        "print('訓練 : {} '.format(\n",
        "    accuracy_score(y_adult_train,\n",
        "                   reg.predict(X_adult_train[features_sel_wrapper_sbg]))))\n",
        "print('検証 : {} '.format(\n",
        "    accuracy_score(y_adult_test,\n",
        "                   reg.predict(X_adult_test[features_sel_wrapper_sbg]))))\n",
        "score_sel_wrapper_sbg = accuracy_score(\n",
        "    y_adult_test, reg.predict(X_adult_test[features_sel_wrapper_sbg]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFCHF4k2QivQ"
      },
      "source": [
        "####2-10-3-3 Bidirectional Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXZFogLFMsEE"
      },
      "source": [
        "#SFSインスタンス化\n",
        "sfsf = SFS(\n",
        "    LogisticRegression(),  #利用するモデル\n",
        "    k_features=(1, 33),  #特徴量の数 1-33個の間でCVスコアベストを探す\n",
        "    forward=True,  #フォワード型\n",
        "    floating=True,  #フローティングの有無 Trueとする\n",
        "    verbose=2,\n",
        "    scoring='accuracy',  #精度指標\n",
        "    cv=5,\n",
        "    n_jobs=-1)\n",
        "\n",
        "sfsf = sfsf.fit(X_adult_train, y_adult_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-U1vimHMvuc"
      },
      "source": [
        "fig1 = plot_sfs(sfsf.get_metric_dict(), kind='std_dev', figsize=(14, 7))\n",
        "plt.title('Bidirectional Generation (w. StdDev)')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XqBfMWzMyoW"
      },
      "source": [
        "#選ばれた特徴量のサブセットでモデルを作成\n",
        "features_sel_wrapper_bg = list(sfsf.k_feature_names_)\n",
        "reg = LogisticRegression().fit(X_adult_train[features_sel_wrapper_bg],\n",
        "                               y_adult_train)\n",
        "print('特徴量 : {} '.format(features_sel_wrapper_bg))\n",
        "print('訓練 : {} '.format(\n",
        "    accuracy_score(y_adult_train,\n",
        "                   reg.predict(X_adult_train[features_sel_wrapper_bg]))))\n",
        "print('検証 : {} '.format(\n",
        "    accuracy_score(y_adult_test,\n",
        "                   reg.predict(X_adult_test[features_sel_wrapper_bg]))))\n",
        "score_sel_wrapper_bg = accuracy_score(\n",
        "    y_adult_test, reg.predict(X_adult_test[features_sel_wrapper_bg]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg88d8mfM4p5"
      },
      "source": [
        "# 2-10-4 Embedded法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdNDOutjM1Ly"
      },
      "source": [
        "#SelectFromModelモジュール読み込み\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "#標準化モジュール読み込む\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HrMO76GQoq8"
      },
      "source": [
        "####2-10-4-1 Lasso回帰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz2mLFItM2pD"
      },
      "source": [
        "#標準化\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_adult_train)\n",
        "X_adult_train_standard = scaler.transform(X_adult_train)\n",
        "X_adult_test_standard = scaler.transform(X_adult_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcOTdq6GM83L"
      },
      "source": [
        "#lasso selectFromModelインスタンス作成\n",
        "embeded_selector = SelectFromModel(\n",
        "    LogisticRegression(C=1.0, penalty=\"l1\", solver='liblinear'),\n",
        "    threshold='mean')\n",
        "embeded_selector.fit(X_adult_train_standard, y_adult_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOfKsjnGM_jN"
      },
      "source": [
        "#選ばれた特徴量のサブセットでモデルを作成\n",
        "features_sel_embedded_lasso = X_adult_train.columns[\n",
        "    embeded_selector.get_support()]\n",
        "reg = LogisticRegression()\n",
        "#モデル作成\n",
        "reg.fit(embeded_selector.transform(X_adult_train), y_adult_train)\n",
        "print('特徴量 : {} '.format(features_sel_embedded_lasso))\n",
        "print('訓練 : {} '.format(\n",
        "    accuracy_score(y_adult_train,\n",
        "                   reg.predict(embeded_selector.transform(X_adult_train)))))\n",
        "print('検証 : {} '.format(\n",
        "    accuracy_score(y_adult_test,\n",
        "                   reg.predict(embeded_selector.transform(X_adult_test)))))\n",
        "score_sel_embedded_lasso = accuracy_score(\n",
        "    y_adult_test, reg.predict(embeded_selector.transform(X_adult_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsogzfrlQvq4"
      },
      "source": [
        "#####2-10-4-2 RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2GqyRHENBfj"
      },
      "source": [
        "#RaondomForest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#RondomForest SelectFromModelインスタンス作成\n",
        "embeded_selector = SelectFromModel(\n",
        "    RandomForestClassifier(\n",
        "        n_estimators=100, random_state=0, min_samples_leaf=50), \"mean\")\n",
        "embeded_selector.fit(X_adult_train, y_adult_train)\n",
        "\n",
        "#選ばれた特徴量のサブセットでモデルを作成\n",
        "features_sel_embedded_rf = X_adult_train.columns[\n",
        "    embeded_selector.get_support()]\n",
        "reg = LogisticRegression()\n",
        "#モデル作成\n",
        "reg.fit(embeded_selector.transform(X_adult_train), y_adult_train)\n",
        "print('特徴量 : {} '.format(features_sel_embedded_rf))\n",
        "print('訓練 : {} '.format(\n",
        "    accuracy_score(y_adult_train,\n",
        "                   reg.predict(embeded_selector.transform(X_adult_train)))))\n",
        "print('検証 : {} '.format(\n",
        "    accuracy_score(y_adult_test,\n",
        "                   reg.predict(embeded_selector.transform(X_adult_test)))))\n",
        "score_sel_embedded_rf = accuracy_score(\n",
        "    y_adult_test, reg.predict(embeded_selector.transform(X_adult_test)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}